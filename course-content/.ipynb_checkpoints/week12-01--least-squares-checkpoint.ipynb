{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [George McNinch](http://gmcninch.math.tufts.edu) Math 87 - Spring 2024\n",
    "\n",
    "# Week 12\n",
    "\n",
    "# Least squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Linear Least Squares\n",
    "====================\n",
    "\n",
    "We are going to begin our discussion of \"least squares\" approximation with an example.\n",
    "\n",
    "Example\n",
    "-------\n",
    "\n",
    "Consider a stretch of highway with four distinct reference points **A**, **B**, **C**, and **D**:\n",
    "\n",
    "[**A**] ----``x1``----- [**B**] ---``x2``------ [**C**] ---``x3``------[**D**]  \n",
    "\n",
    "Write ``x1`` = **AB** for the distance from **A** to **B**, ``x2`` = **BC**, ``x3`` = **CD**.\n",
    "\n",
    "We take some measurements -- which potentially reflect errors -- , and we seek the *best approximation* to the distances ``x1, x2, x3``.\n",
    "\n",
    "The measurements taken are as follows:\n",
    "\n",
    "|||||||\n",
    "| ------: | ------:| ------:| ------:| ------:| ------:|\n",
    "| segment | **AD** | **AC** | **BD** | **AB** | **CD** |\n",
    "| length  | 89 m   | 67 m   | 53 m   | 35 m   | 20 m   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Thus the observations suggest the following equations:\n",
    "\n",
    "``(1)  x1 + x2 + x3 = 89``  \n",
    "``(2)  x1 + x2      = 67``  \n",
    "``(3)       x2 + x3 = 53``  \n",
    "``(4)  x1           = 35``  \n",
    "``(5)            x3 = 20``\n",
    "\n",
    "These equations aren't compatible, though. Note e.g. that equations ``(3) -- (5)`` indicate the following:\n",
    "\n",
    "``x1 = 35, x3 = 20, x2 = 53-20 = 33``\n",
    "\n",
    "but then we find that\n",
    "\n",
    "``x1 + x2 + x3 = 35 + 33 + 20 = 88``\n",
    "\n",
    "which is incompatible with ``(1)``.\n",
    "\n",
    "And we find that \n",
    "\n",
    "``x1 + x2 = 35 + 33 = 68`` \n",
    "\n",
    "which is incompatible with ``(2)``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Let's formulate these equalities in matrix form.\n",
    "\n",
    "Thus let \n",
    "$$A = \\begin{pmatrix}\n",
    "1 & 1 & 1 \\\\\n",
    "1 & 1 & 0 \\\\\n",
    "0 & 1 & 1 \\\\\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 \n",
    "\\end{pmatrix}, \\quad\n",
    "\\mathbf{x} = \\begin{pmatrix}\n",
    "x_1 \\\\ x_2 \\\\ x_3 \n",
    "\\end{pmatrix},\n",
    "\\quad\n",
    "\\mathbf{b} = \\begin{pmatrix}\n",
    "89 \\\\ 67 \\\\ 53 \\\\ 35 \\\\ 20\n",
    "\\end{pmatrix}.$$\n",
    "\n",
    "With these notations, the above equations suggest that $A\\mathbf{x}$ should be equal to $\\mathbf{b}$.\n",
    "\n",
    "Our observation(s) in the preceding slides show, however, that the system of equations\n",
    "$A \\mathbf{x} = \\mathbf{b}$\n",
    "is *inconsistent* (i.e. there is no vector $\\mathbf{x}$ which makes the equation true).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Residual\n",
    "--------\n",
    "\n",
    "In general, given an $m\\times n$ matrix $A$, a column vector $\\mathbf{b} \\in \\mathbb{R}^m$ and an equation\n",
    "$A \\mathbf{x} = \\mathbf{b}$, we instead look at the so-called *residual*\n",
    "\n",
    "$$\\mathbf{r} = \\mathbf{b} - \\mathbf{A}\\mathbf{x},$$\n",
    "\n",
    "and *minimize* this residual.\n",
    "\n",
    "More precisely, we want to minimize the *magnitude* (or *length*) of this vector.\n",
    "\n",
    "Thus if $\\mathbf{r} = \\begin{pmatrix} r_1 & \\cdots & r_m \\end{pmatrix}^T$, we must minimize the quantity\n",
    "\n",
    "$$\\Vert\\mathbf{r}\\Vert = \\left(\\sum_{i=1}^m r_i^2 \\right)^{1/2}$$\n",
    "\n",
    "Here $\\Vert \\mathbf{r} \\Vert$ is the magnitude, also called the Euclidean norm, of the vector $\\mathbf{r}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "In fact, because $f(x) = \\sqrt{x}$ is an increasing function of $x$, we instead minimize the *square* of the magnitude of $\\mathbf{r}$::\n",
    "\n",
    "$$\\Vert\\mathbf{r}\\Vert^2 = \\sum_{i=1}^m r_i^2$$\n",
    "\n",
    "Thus, we wish to find\n",
    "\n",
    "$$\\min_{\\mathbf{x}} \\Vert \\mathbf{r} \\Vert^2 = \\min_{\\mathbf{x}} \\Vert \\mathbf{b} - A \\mathbf{x} \\Vert^2\n",
    "= \\min_{x_1,x_2,\\dots,x_n} \\sum_{i=1}^m \\left( b_i - \\sum_{j=1}^n A_{ij} x_j \\right)^2$$\n",
    "\n",
    "The idea behind this minimization is to first compute for $1 \\le k \\le n$ \n",
    "the partial derivatives $\\dfrac{\\partial F}{\\partial x_k}$ of the function\n",
    "$$F(x_1,x_2,\\dots,x_n)  = \\sum_{i=1}^m \\left( b_i - \\sum_{j=1}^n A_{ij} x_j \\right)^2$$\n",
    "\n",
    "Critical points - and thus possible minima - for $F$ occur at points $\\mathbf{x}$ for which\n",
    "all $\\dfrac{\\partial F}{\\partial x_k}(\\mathbf{x}) = 0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Now,\n",
    "$$\\dfrac{\\partial F}{\\partial x_k} = \\sum_{i=1}^m 2\\left(b_i - \\sum_{j=1}^n A_{ij} x_j\\right)(-A_{ik})\n",
    "= 2\\left( \\sum_{i=1}^m (-A_{ik}b_i) + \\sum_{i=1}^m A_{ik} \\sum_{j=1}^n A_{ij}x_j \\right)$$\n",
    "\n",
    "and this expression is equal to the $k$-th coefficient of the vector\n",
    "$$2\\left(-A^T \\mathbf{b} + A^T A \\mathbf{x} \\right)$$\n",
    "\n",
    "Thus, the condition $\\dfrac{\\partial F}{\\partial x_k} = 0$ for all $k$ is equivalent to the so-called *normal equations*:\n",
    "\n",
    "$$(\\diamondsuit) \\quad A^T A \\mathbf{x} = A^T \\mathbf{b}.$$\n",
    "\n",
    "Thus the solutions $\\mathbf{x}$ to the normal equations $(\\diamondsuit)$ are precisely the critical points of the function $F$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Recall that $A \\in \\mathbb{R}^{m \\times n}$. Thus, $A^T \\in \\mathbb{R}^{n \\times m}$ so that \n",
    "the matrix $A^TA$ is $n \\times n$; in particular, $A^T A$ is always a square matrix.\n",
    "\n",
    "Moreover, $A^T A$ is *symmetric*, since\n",
    "\n",
    "$$(A^T A)^T = A^T (A^T)^T = A^T A.$$\n",
    "\n",
    "We are interested here in the case of *overdetermined systems* -- i.e. in the case where $A$ has more rows than columns (\"more equations than variables\"). Thus $m \\ge n$.\n",
    "\n",
    "We also are interested in the case where $A$ has rank $n$ -- i.e.$A$ has $n$ linearly independent columns -- since otherwise we don't expect to have enough information to find $\\mathbf{x}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Proposition\n",
    "-----------\n",
    "\n",
    "Let $A \\in \\mathbb{R}^{m \\times n}$, suppose that $m \\ge n$ and that $A$ has rank $n$.\n",
    "Then $A^T \\cdot A$ is invertible.\n",
    "\n",
    "**Proof:**\n",
    "\n",
    "Since $A^T \\cdot A$ is an $n \\times n$ square matrix, the proposition will follow if we argue\n",
    "that the null space $\\operatorname{Null}(A^TA)$ is zero. So: suppose that $\\mathbf{v} \\in \\operatorname{Null}(A^TA)$.\n",
    "\n",
    "Thus $A^TA\\mathbf{v} = 0$ and thus also $\\mathbf{v}^T A^T \\cdot A \\mathbf{v} = 0$.\n",
    "\n",
    "Now,\n",
    "$$0 = \\mathbf{v}^T A^T \\cdot A \\mathbf{v} = (A \\mathbf{v})^T(A \\mathbf{v})$$\n",
    "\n",
    "and of course for any vector $\\mathbf{w}$, we know that \n",
    "$$0 = \\mathbf{w}^T \\mathbf{w} \\implies \\mathbf{w} = \\mathbf{0}.$$\n",
    "\n",
    "We now conclude that $A\\mathbf{v} = 0$, so $\\mathbf{v} \\in \\operatorname{Null}(A)$. Since\n",
    "$A$ has rank $n$, the Null space of $A$ is equal to zero, and we condlue that $\\mathbf{v} = \\mathbf{0}$. \n",
    "\n",
    "We have now proved that $\\operatorname{Null}(A^TA)$ is zero, as required.\n",
    "\n",
    "**Remark:** What we have really showed is that the symmetric matrix $A^T A$ is *definite*:\n",
    "$\\mathbf{v}^TA^T A \\mathbf{v} = 0 \\implies \\mathbf{v} = \\mathbf{0}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "We finally claim that this solution must minimize the magnitude of the residual.\n",
    "\n",
    "This depends on a \"second derivative test\" argument for which I'm not going to give full details.\n",
    "The main point is that the \"second derivative\" in this context -- known as the Hessian -- concides\n",
    "with the matrix $2A^T A$. Now, under our assumptions the matrix $A^T A$ is postive definite, and it follows\n",
    "that $\\mathbf{x}_0$ is a global minimum for the magnitude of the residual!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Return to the example\n",
    "----------------------\n",
    "\n",
    "Recall that\n",
    "$$A = \\begin{pmatrix}\n",
    "1 & 1 & 1 \\\\\n",
    "1 & 1 & 0 \\\\\n",
    "0 & 1 & 1 \\\\\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 \n",
    "\\end{pmatrix}, \\quad\n",
    "\\mathbf{x} = \\begin{pmatrix}\n",
    "x_1 \\\\ x_2 \\\\ x_3 \n",
    "\\end{pmatrix},\n",
    "\\quad\n",
    "\\mathbf{b} = \\begin{pmatrix}\n",
    "89 \\\\ 67 \\\\ 53 \\\\ 35 \\\\ 20\n",
    "\\end{pmatrix}.$$\n",
    "\n",
    "So to minimize the magnitude of the residual, we must solve the normal equations:\n",
    "\n",
    "$$A^T A \\mathbf{x} = A^T \\mathbf{b}.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Now \n",
    "$$A^T A = \n",
    "\\begin{pmatrix}\n",
    "1 & 1 & 0 & 1 & 0 \\\\\n",
    "1 & 1 & 1 & 0 & 0 \\\\\n",
    "1 & 0 & 1 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\cdot\n",
    "\\begin{pmatrix}\n",
    "1 & 1 & 1 \\\\\n",
    "1 & 1 & 0 \\\\\n",
    "0 & 1 & 1 \\\\\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 \n",
    "\\end{pmatrix}\n",
    "= \\begin{pmatrix}\n",
    "3 & 2 & 1 \\\\\n",
    "2 & 3 & 2 \\\\\n",
    "1 & 2 & 3\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "and\n",
    "$$A^T \\mathbf{b} = \\begin{pmatrix}\n",
    "191 \\\\ 209\\\\ 162\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "So we need to solve the equation\n",
    "\n",
    "$$\\begin{pmatrix}\n",
    "3 & 2 & 1 \\\\\n",
    "2 & 3 & 2 \\\\\n",
    "1 & 2 & 3\n",
    "\\end{pmatrix} \\cdot\n",
    "\\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} =\n",
    "\\begin{pmatrix}\n",
    "191 \\\\ 209\\\\ 162\n",
    "\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([35.125, 32.5  , 20.625]), 1.1726039399558574]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "\n",
    "A= np.array([[1,1,1],[1,1,0],[0,1,1],[1,0,0],[0,0,1]])\n",
    "b = np.array([89,67,53,35,20])\n",
    "\n",
    "\n",
    "x0=la.solve(A.T @ A, A.T @ b)\n",
    "\n",
    "def residual(x):\n",
    "    return b - A @ x\n",
    "\n",
    "def magnitude(x):\n",
    "    return np.sqrt(x@x)\n",
    "    \n",
    "[x0,magnitude(residual(x0))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Thus the *least squares solution* is\n",
    "\n",
    "$$\\mathbf{x}_0 = \\begin{pmatrix}\n",
    "35.125 \\\\ 32.5 \\\\ 20.625\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\\Vert \\mathbf{b} - A \\mathbf{x}_0\\Vert \\approx 1.1726$$\n",
    "\n",
    "Recall that our \"first guess\" for a solution (based on some of the measurements) was\n",
    "\n",
    "$$\\mathbf{x}_1 = \\begin{pmatrix}\n",
    "35 \\\\ 33 \\\\ 20\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "The residual is indeed larger for $x_1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.array([35,33,20])\n",
    "\n",
    "magnitude(residual(x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's note that ``numpy`` already implements this least-squares functionality:\n",
    "\n",
    "-- you can [read more about it here](https://numpy.org/doc/stable/reference/generated/numpy.linalg.lstsq.html#numpy.linalg.lstsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35.125, 32.5  , 20.625])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=la.lstsq(A,b,rcond=None)\n",
    "res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example recapitulated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider towns in a certain area labeled `[a,b,c,d,e,f,g,h,i,j]`.\n",
    "You have hired someone to estimate the population of these towns, but they\n",
    "got confused and have reported the populations of *pairs* of towns. \n",
    "\n",
    "Thus you have the following data:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('a', 'b'): 21.21,\n",
       " ('a', 'c'): 24.35,\n",
       " ('a', 'd'): 34.57,\n",
       " ('a', 'e'): 32.72,\n",
       " ('a', 'f'): 36.14,\n",
       " ('a', 'g'): 17.21,\n",
       " ('a', 'h'): 26.41,\n",
       " ('a', 'i'): 29.92,\n",
       " ('a', 'j'): 32.84,\n",
       " ('b', 'c'): 29.09,\n",
       " ('b', 'd'): 33.78,\n",
       " ('b', 'e'): 40.63,\n",
       " ('b', 'f'): 44.46,\n",
       " ('b', 'g'): 17.03,\n",
       " ('b', 'h'): 30.58,\n",
       " ('b', 'i'): 32.7,\n",
       " ('b', 'j'): 31.19,\n",
       " ('c', 'd'): 30.08,\n",
       " ('c', 'e'): 37.3,\n",
       " ('c', 'f'): 39.4,\n",
       " ('c', 'g'): 20.44,\n",
       " ('c', 'h'): 28.34,\n",
       " ('c', 'i'): 31.07,\n",
       " ('c', 'j'): 36.78,\n",
       " ('d', 'e'): 41.44,\n",
       " ('d', 'f'): 47.97,\n",
       " ('d', 'g'): 28.51,\n",
       " ('d', 'h'): 38.0,\n",
       " ('d', 'i'): 38.71,\n",
       " ('d', 'j'): 39.24,\n",
       " ('e', 'f'): 59.61,\n",
       " ('e', 'g'): 29.19,\n",
       " ('e', 'h'): 35.09,\n",
       " ('e', 'i'): 42.18,\n",
       " ('e', 'j'): 46.8,\n",
       " ('f', 'g'): 34.14,\n",
       " ('f', 'h'): 46.71,\n",
       " ('f', 'i'): 48.07,\n",
       " ('f', 'j'): 49.53,\n",
       " ('g', 'h'): 23.46,\n",
       " ('g', 'i'): 22.13,\n",
       " ('g', 'j'): 24.21,\n",
       " ('h', 'i'): 29.03,\n",
       " ('h', 'j'): 32.51,\n",
       " ('i', 'j'): 38.17}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "p_est ={('a', 'b'): 21.21,\n",
    " ('a', 'c'): 24.35,\n",
    " ('a', 'd'): 34.57,\n",
    " ('a', 'e'): 32.72,\n",
    " ('a', 'f'): 36.14,\n",
    " ('a', 'g'): 17.21,\n",
    " ('a', 'h'): 26.41,\n",
    " ('a', 'i'): 29.92,\n",
    " ('a', 'j'): 32.84,\n",
    " ('b', 'c'): 29.09,\n",
    " ('b', 'd'): 33.78,\n",
    " ('b', 'e'): 40.63,\n",
    " ('b', 'f'): 44.46,\n",
    " ('b', 'g'): 17.03,\n",
    " ('b', 'h'): 30.58,\n",
    " ('b', 'i'): 32.7,\n",
    " ('b', 'j'): 31.19,\n",
    " ('c', 'd'): 30.08,\n",
    " ('c', 'e'): 37.3,\n",
    " ('c', 'f'): 39.4,\n",
    " ('c', 'g'): 20.44,\n",
    " ('c', 'h'): 28.34,\n",
    " ('c', 'i'): 31.07,\n",
    " ('c', 'j'): 36.78,\n",
    " ('d', 'e'): 41.44,\n",
    " ('d', 'f'): 47.97,\n",
    " ('d', 'g'): 28.51,\n",
    " ('d', 'h'): 38.0,\n",
    " ('d', 'i'): 38.71,\n",
    " ('d', 'j'): 39.24,\n",
    " ('e', 'f'): 59.61,\n",
    " ('e', 'g'): 29.19,\n",
    " ('e', 'h'): 35.09,\n",
    " ('e', 'i'): 42.18,\n",
    " ('e', 'j'): 46.8,\n",
    " ('f', 'g'): 34.14,\n",
    " ('f', 'h'): 46.71,\n",
    " ('f', 'i'): 48.07,\n",
    " ('f', 'j'): 49.53,\n",
    " ('g', 'h'): 23.46,\n",
    " ('g', 'i'): 22.13,\n",
    " ('g', 'j'): 24.21,\n",
    " ('h', 'i'): 29.03,\n",
    " ('h', 'j'): 32.51,\n",
    " ('i', 'j'): 38.17}\n",
    "\n",
    "p_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value `mdist[('a','b')] == 21.21` means that the sum of the populations of towns `a` and `b` is 21.21 thousand people.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's form the matrix `M` and vector `b` so that `M @ x == b` expresses these distance relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "towns = [ 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j' ]\n",
    "pairs = list(p_est.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1]]),\n",
       " array([21.21, 24.35, 34.57, 32.72, 36.14, 17.21, 26.41, 29.92, 32.84,\n",
       "        29.09, 33.78, 40.63, 44.46, 17.03, 30.58, 32.7 , 31.19, 30.08,\n",
       "        37.3 , 39.4 , 20.44, 28.34, 31.07, 36.78, 41.44, 47.97, 28.51,\n",
       "        38.  , 38.71, 39.24, 59.61, 29.19, 35.09, 42.18, 46.8 , 34.14,\n",
       "        46.71, 48.07, 49.53, 23.46, 22.13, 24.21, 29.03, 32.51, 38.17]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sbv(i,n):\n",
    "    # return the ith standard basis vector of length n\n",
    "    return np.array([1 if j == i else 0 for j in range(n)])\n",
    "\n",
    "def sbv_list(elem,ls):\n",
    "    # return the standard basis vector determined by the position of `elem` in the list `ls`\n",
    "    return sbv(list(ls).index(elem),len(ls))\n",
    "\n",
    "M = np.array([sbv_list(x,towns) + sbv_list(y,towns) for (x,y) in p_est.keys()])\n",
    "\n",
    "b = np.array([p_est[x] for x in p_est.keys()])\n",
    "\n",
    "(M,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `least squares` to find the best solution to `M @ x == b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.63041667, 13.79291667, 13.31541667, 20.24666667, 24.32916667,\n",
       "       29.46291667,  5.74916667, 14.97541667, 17.70666667, 20.11791667])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = la.lstsq(M,b,rcond=None)\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([24.42333333, 23.94583333, 30.87708333, 34.95958333, 40.09333333,\n",
       "        16.37958333, 25.60583333, 28.33708333, 30.74833333, 27.10833333,\n",
       "        34.03958333, 38.12208333, 43.25583333, 19.54208333, 28.76833333,\n",
       "        31.49958333, 33.91083333, 33.56208333, 37.64458333, 42.77833333,\n",
       "        19.06458333, 28.29083333, 31.02208333, 33.43333333, 44.57583333,\n",
       "        49.70958333, 25.99583333, 35.22208333, 37.95333333, 40.36458333,\n",
       "        53.79208333, 30.07833333, 39.30458333, 42.03583333, 44.44708333,\n",
       "        35.21208333, 44.43833333, 47.16958333, 49.58083333, 20.72458333,\n",
       "        23.45583333, 25.86708333, 32.68208333, 35.09333333, 37.82458333]),\n",
       " array([-3.21333333,  0.40416667,  3.69291667, -2.23958333, -3.95333333,\n",
       "         0.83041667,  0.80416667,  1.58291667,  2.09166667,  1.98166667,\n",
       "        -0.25958333,  2.50791667,  1.20416667, -2.51208333,  1.81166667,\n",
       "         1.20041667, -2.72083333, -3.48208333, -0.34458333, -3.37833333,\n",
       "         1.37541667,  0.04916667,  0.04791667,  3.34666667, -3.13583333,\n",
       "        -1.73958333,  2.51416667,  2.77791667,  0.75666667, -1.12458333,\n",
       "         5.81791667, -0.88833333, -4.21458333,  0.14416667,  2.35291667,\n",
       "        -1.07208333,  2.27166667,  0.90041667, -0.05083333,  2.73541667,\n",
       "        -1.32583333, -1.65708333, -3.65208333, -2.58333333,  0.34541667]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(M @ x[0],b - M @ x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
